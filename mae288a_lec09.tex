\mainmatter%
\setcounter{page}{1}

\lectureseries[\course]{\course}

\auth[\lecAuth]{Lecturer: \lecAuth\\ Scribe: \scribe}
\date{October 27, 2009}

\setaddress%

% the following hack starts the lecture numbering at 9
\setcounter{lecture}{8}
\setcounter{chapter}{8}

\lecture{Dynamics of Markov Chains}

\section{Discrete Space, Discrete Time Markov Chains}
Continuous time Markov chains exist but we will only be considering discrete time in this course.
A Markov chain, $\mathbb{X}$, in discrete time could be $\mathbb{X}\in\mathbb{N}=\{1,2,3,\ldots\}$.
Mostly we will restrict our discussion to a finite state space such that $\mathbb{X}=\{1,2,3,\ldots,N\}$ for $N<\infty$.
An example of this is vehicles that have three states where $\mathbb{X}=\{\text{broken,~fine,~needs~maintenance}\}$.

\begin{definition}
The transition probability is

\begin{equation*}
\pij = P(\xi_{t+1}=j|\xi_t=i)
\end{equation*}

where $\xi_t\in\mathbb{X}$.
\end{definition}

We will assume the Markov property applies, so
\begin{align*}
P(\xi_{t+1}\in\mathcal{A} | \xi_t=i_t, \xi_{t-1}=i_{t-1},\ldots,\xi_0=i_0) = P(\xi_{t+1}\in\mathcal{A}|\xi_t=i_t)
\end{align*}

\section{Dynamics}
The dynamics of Markov chains are given by the transition probability, $\mathbb{P}$.
Note that de Morgan's Law says that

\begin{equation*}
A\cap[B\cup C] = [A\cap B] \cup [A\cap C]
\end{equation*}

This gives
\begin{align*}
P\left(\xi_{t+2}=j | \xi_t=i\right) &= P\left(\{\xi_{t+2}=j\} \cap \left[\bigcup_{k\in\mathbb{X}}\{\xi_{t+1}=k\}\right] | \{\xi_t=i\}\right) \\
&= P\left(\{\xi_{t+2}=j\} \cap \left[\bigcup_{k\in\mathbb{X}}\{\xi_{t+1}=k\} \cap \{\xi_t=i\}\right]\right) \\
&\qquad / P(\xi_t=i) \\
&= P\left(\bigcup_{k\in\mathbb{X}}[\{\xi_{t+2}=j\} \cap \{\xi_{t+1}=k\} \cap \{\xi_t=i\}]\right) \\
&\qquad / P(\xi_t=i) \\
&= \sum_{k\in\mathbb{X}} P(\{\xi_{t+2}=j\} \cap \{\xi_{t+1}=k\} \cap \{\xi_t=i\}) \\
&\qquad / P(\xi_t=i) \\
&= \sum_{k\in\mathbb{X}} P(\xi_{t+2}=j | \xi_{t+1}=k,\xi_t=i) \cdot P(\xi_{t+1}=k,\xi_t=i) \\
&\qquad / P(\xi_t=i) \\
&= \sum_{k\in\mathbb{X}} P(\xi_{t+2}=j | \xi_{t+1}=k) \cdot P(\xi_{t+1}=k,\xi_t=i) \\
&\qquad \cdot P(\xi_t=i) / P(\xi_t=i) \\
&= \sum_{k\in\mathbb{X}} P(\xi_{t+2}=j | \xi_{t+1}=k) \cdot P(\xi_{t+1}=k,\xi_t=i) \\
&= \sum_{k\in\mathbb{X}} \mathbb{P}_{k,j}\mathbb{P}_{i,k} = \sum_{k\in\mathbb{X}} \mathbb{P}_{i,k}\mathbb{P}_{k,j} = {\left[\mathbb{P}^2\right]}_{i,j}
\end{align*}
Then, let $p_t$ be a $1\times n$ vector, $p_{t_i}={[p_t]}_i=P(\xi_t=i)$.
Since it is a probability we must have $p_{t_i}\in[0,1]$ and

\begin{equation*}
\sumi p_{t_i}=1
\end{equation*}

Now let $S^N=\{q\in\mathbb{R}^n|q_i\in[0,1],\sum q_i=1\}$, where $\sum q_i=1$ is the simplex.
See Figure~\ref{fig:09s2s3}.
These probabilities define the state.

\begin{equation*}
p_{{t+1}_i} = P(\xi_{t+1}=i) = \sum_j P(\xi_{t+1}=i|\xi_t=j)P(\xi_t=j) = \pji p_{t_i}
\end{equation*}

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09s2s3}
\caption{Probability spaces for two and three variables.}%
\label{fig:09s2s3}
\end{figure}

\section{Uncontrolled Markov Dynamics}
The uncontrolled Markov dynamics are
\begin{align*}
p_{t+1} &= \mathbb{P}^T p_t \\
p_{t+1} &= p_t\mathbb{P}
\end{align*}
The first expression is for column vectors, $\dim(p_t)=n\times 1$, and the second expression is for row vectors, $\dim(p_t)=1\times n$.
We will assume column vectors in this course.

\begin{example}
Consider a birth-death process of cells in a petri dish.
The state space is given by $\mathbb{X}=\{0,1,2,\ldots\}$ so we are working in infinite space.
Let $q$ be the probability that a cell dies in one time step, $p$ be the probability that a cell splits in one time step and $r=1-p-q$ the probability that neither event happens.
Starting at $t=0$ with no cells in the petri dish has a transitional probability of

\begin{equation*}
\mathbb{P}_{0,j} = \begin{cases} 1, & j=0 \\ 0, & j\neq0 \end{cases}
\end{equation*}

Moving forward in time shows
\begin{align*}
\mathbb{P}_{1,j} &= \begin{cases} q, & j=0 \\ r, & j=1 \\ p, & j=2 \end{cases} \\
\mathbb{P}_{2,j} &= \begin{cases} q^2, & j=0 \\ 2qr, & j=1 \\ 2pr, & j=2 \\ r^2+2pq, & j=3 \\ r^2, & j=4 \\ 0, & j>4 \end{cases}
\end{align*}
which gives
\begin{align*}
\pij = \left[\begin{array}{c c c c c c c}
1 & 0 & 0 & 0 & 0 & 0 & \cdots \\
q & r & p & 0 & 0 & 0 & \cdots \\
q^2 & 2qr & 2pr & r^2+2pq & r^2 & 0 & \cdots \\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{array}\right]
\end{align*}
$\lozenge$
\end{example}

\begin{example}
Here we will look at gambling where the player starts with $\$x$ and the house starts with $\$y$, giving a total of $\$x+y$.
Let $\xi_t=x+1$.
Let $\xi_t$ be the player holdings plus one and $\mathbb{X}=\{1,2,\ldots,N\}$ with $N=x+y+1$.
At each step the player wins with probability $p$ and loses with probability $q=1-p$.
The probability transistion matrix is given by

\begin{equation*}
\pij = \begin{cases} 1, & j=1 \\ 0, & j\neq1 \end{cases}
\end{equation*}

For $N=5$ this results in
\begin{align*}
\mathbb{P} = \left[\begin{array}{c c c c c}
1 & 0 & 0 & 0 & 0 \\
q & 0 & p & 0 & 0 \\
0 & q & 0 & p & 0 \\
0 & 0 & q & 0 & p \\
0 & 0 & 0 & 0 & 1
\end{array}\right]
\end{align*}
If $p_0 = \left[\begin{array}{c c c c c} 0 & 0 & 1 & 0 & 0 \end{array}\right]^T$, then $p_1=\mathbb{P}^Tp_0 = \left[\begin{array}{c c c c c} 0 & q & 0 & p & 0 \end{array}\right]^T$ and $p_2=\mathbb{P}^Tp_1=\left[\begin{array}{c c c c c} q^2 & 0 & 2pq & 0 & p^2 \end{array}\right]^T$.
These are absorbing states so $p_3=\mathbb{P}^Tp_2=\left[\begin{array}{c c c c c} q^2 & 2pq^2 & 0 & 2p^2q & p^2 \end{array}\right]^T$.
$\lozenge$
\end{example}

\begin{definition}
A \textit{Markov chain} is defined by $ (\mathbb{X},\mathbb{P})$.
\end{definition}

\begin{definition}
$i$ is \textit{accessible} from $j$, $j\rightarrow~i$, if there exists $n>0$ such that $P (\xi_{t+n}=i|\xi_t=j)>0$ including $n=0$.
\end{definition}

\begin{definition}
$i$ \textit{communicates} with $j$, $i\leftrightarrow~j$, if $i\rightarrow~j$ and $j\rightarrow~i$.
\end{definition}
In the gambling example all states communicate because $2\leftrightarrow~3\leftrightarrow~4\leftrightarrow\ldots\leftrightarrow~N-1$.
We also have $2\rightarrow~1$, $3\rightarrow~1$, $4\rightarrow~1$, but $1\nleftrightarrow~2$.

\begin{definition}
\label{def:absorbing}
If $\mathbb{P}_{i,i}=1$ then state $i$ is \textit{absorbing}.
\end{definition}

\begin{definition}
A Markov chain is \textit{irreducible} if $i\leftrightarrow~j~\forall~i,j$.
\end{definition}
In the gambling example the states are not irreducible because $1\nleftrightarrow~2$.

\begin{definition}
Let $\mathbb{X}$ be a set.
Then '$\sim$' is an \textit{equivalence relation} on $\mathbb{X}$ if
\begin{itemize}
\item $x\sim~x~\forall~x\in\mathbb{X}$
\item $x\sim~y \Leftrightarrow~y\sim~x~\forall~x,y\in\mathbb{X}$
\item $x\sim~y$, $y\sim~z \Rightarrow~x\sim~z~\forall~x,y,z\in\mathbb{X}$
\end{itemize}
\end{definition}

\begin{theorem}
Communication, $\leftrightarrow$, is an equivalence relation.
\end{theorem}

\begin{definition}
Suppose $A_i\subseteq~\mathbb{X}~\forall~i\in\mathcal{I}, A_i\cap~A_j=\null$ if $i\neq~j$ and

\begin{equation*}
\bigcup_{i\in\mathcal{I}}A_i = \mathbb{X}
\end{equation*}

then $\{A_i\}_{i\in\mathcal{I}}$ \textit{partitions} $\mathbb{X}$.% chktex 3
\end{definition}

\begin{theorem}
An equivalence relation on $\mathbb{X}$ partitions $\mathbb{X}$ into equivalence classes.
\end{theorem}

\begin{example}
Using Figure~\ref{fig:09mc5} we can see that state $5$ is absorbing and $1\leftrightarrow~2\leftrightarrow~3$.
The equivalence classes are
\begin{align*}
A_1 &= \{1,2,3\} \\
A_2 &= \{4\} \\
A_3 &= \{5\}
\end{align*}
$\lozenge$
\end{example}

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09mc5}
\caption{Five state Markov chain.}%
\label{fig:09mc5}
\end{figure}

\begin{definition}
The \textit{period} of state $i$, $d(i)$, is the greatest common divisor (GCD) of the set $\{n\geq1|\mathbb{P}_{i,i}^n>0\}$.
If ${[\mathbb{P}^n]}_{i,j} = 0~\forall n\geq1$, then $d(i)=0$.
So $d(i) = \text{GCD}(\{n\geq1,{[\mathbb{P}^]}_{i,j}>0\})$.
\end{definition}

\begin{theorem}%
\label{th:periodicity}
If $i\leftrightarrow j$ then $d(i)=d(j)$.
\end{theorem}

\begin{example}
$A_1=\{1,2,3,4,5\}$ and $A_6=\{6\}$ are equivalence classes.
Then

\begin{equation*}
P(\xi_{t+2}=3|\xi_t=3) = \mathbb{P}_{3,5}\mathbb{P}_{5,3} = 0.25> 0
\end{equation*}

We can also see $d(3)=\text{GCD}(\{2,4,6,8,\ldots\})=2$.
So, by Theorem~\ref{th:periodicity}

\begin{equation*}
d(1)=d(2)=d(3)=d(4)=d(5)=2 \Rightarrow \mathbb{P}_{6,6}^n=1~\forall n \therefore d(6)=1
\end{equation*}

See Figure~\ref{fig:09mc6}.
$\lozenge$
\end{example}

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09mc6}
\caption{Six state Markov chain.}%
\label{fig:09mc6}
\end{figure}

\begin{definition}
Given a matrix $\mathbb{P}$ such that $\pij\in[0,1]~\forall i,j$, then $\sum_j\pij=1$.
$\mathbb{P}$ is called a \textit{stochastic matrix}.
\end{definition}

\begin{definition}
If $d(i)=1~\forall i$ then the Markov chain is \textit{aperiodic}.
\end{definition}

\begin{example}
Let

\begin{equation*}
\mathbb{P} = \left[\begin{array}{c c} 0 & 1 \\ \frac{1}{2} & \frac{1}{2} \end{array}\right]
\end{equation*}

Clearly $d (2)=1$ and $d (1)=1$.
This is aperiodic and irreducible.
See Figure~\ref{fig:09mc2}.
$\lozenge$
\end{example}

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09mc2}
\caption{Two state Markov chain.}%
\label{fig:09mc2}
\end{figure}

\begin{example}
Let

\begin{equation*}
\mathbb{P} = \left[\begin{array}{c c c} 0 & 1 & 0 \\ \frac{1}{2} & 0 & \frac{1}{2} \\ 0 & 1 & 0 \end{array}\right]
\end{equation*}

This Markov chain is irreducible.
See Figure~\ref{fig:09mc3}.
Also, $d (i)=2~\forall~i$.
We also have
\begin{align*}
\begin{split}
p_0 &= \left[\begin{array}{c} q_1 \\ q_2 \\ q_3 \end{array}\right]
\end{split}
\begin{split}
p_1 &= \mathbb{P}^Tp_0 = \left[\begin{array}{c} \frac{q_2}{2} \\ q_1+q_3 \\ \frac{q_2}{2} \end{array}\right]
\end{split} \\
\begin{split}
p_2 &= \mathbb{P}^Tp_1 = \left[\begin{array}{c} \frac{q_1+q_3}{2} \\ q_2 \\ \frac{q_1+q_3}{2} \end{array}\right]
\end{split}
\begin{split}
p_3 &= \mathbb{P}^Tp_2 = \left[\begin{array}{c} \frac{q_2}{2} \\ q_1+q_3 \\ \frac{q_2}{2} \end{array}\right]
\end{split}
\end{align*}
Since $p_3=p_1 \therefore p_{2n}=p_2$, $p_{2n-1}=p_1~\forall n\geq1$ and the dynamics oscillate.
Also, it can be seen that
\begin{align*}
\begin{split}
\mathbb{P}^2 = \left[\begin{array}{c c c} \frac{1}{2} & 0 & \frac{1}{2} \\ 0 & 1 & 0 \\ \frac{1}{2} & 0 & \frac{1}{2} \end{array}\right]
\end{split}
\begin{split}
\mathbb{P}^3 = \left[\begin{array}{c c c} 0 & 1 & 0 \\ \frac{1}{2} & 0 & \frac{1}{2} \\ 0 & 1 & 0 \end{array}\right]
\end{split}
\end{align*}
So $\mathbb{P}$ is periodic (oscillates) too.
$\lozenge$
\end{example}

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09mc3}
\caption{Three state Markov chain.}%
\label{fig:09mc3}
\end{figure}

\subsection{Infinite Size Gets Strange}
See Figure~\ref{fig:09mcinf}.
Suppose
\begin{align*}
p_0 = \left[\begin{array}{c} 1 \\ 0 \\ 0 \\ 0 \\ \vdots \end{array}\right],
\qquad p_1 = \left[\begin{array}{c} \frac{1}{4} \\ \frac{3}{4} \\ 0 \\ 0 \\ \vdots \end{array}\right],
\qquad p_2 = \left[\begin{array}{c} \frac{1}{4} \\ \frac{3}{16} \\ \frac{9}{16} \\ 0 \\ \vdots \end{array}\right],
\qquad \ldots
\end{align*}
This leads to $\sum p_{t_i}=1$, but $p_{t_i}\rightarrow 0~\forall i$ as $i\to\infty$.

\begin{figure}[ht!]
\centering
\includegraphics[width=.4\textwidth]{images/09mcinf}
\caption{Infinite state Markov chain.}%
\label{fig:09mcinf}
\end{figure}

\begin{definition}
$\Pi\in S^N = S^{\#\mathbb{X}}$ such that $\Pi=\mathbb{P}^T\Pi$ is called a \textit{stationary distribution} for the Markov chain $(\mathbb{X},\mathbb{P})$.
\end{definition}

\begin{example}
Suppose

\begin{equation*}
\bar{p}=\lim_{t\to\infty}p_t = \lim_{t\to\infty}{(\mathbb{P}^T)}^t p_0
\end{equation*}

then

\begin{equation*}
\mathbb{P}^T\bar{p}=\lim_{t\to\infty}\mathbb{P}^T{(\mathbb{P}^T)}^t p_t = \lim_{t\to\infty}{(\mathbb{P}^T)}^{t+1}p_0=\bar{p}
\end{equation*}

$\therefore \bar{p}$ is a stationary distribution.
$\lozenge$
\end{example}
