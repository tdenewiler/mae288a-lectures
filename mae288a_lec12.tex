\mainmatter%
\setcounter{page}{1}

\lectureseries[\course]{\course}

\auth[\lecAuth]{Lecturer: \lecAuth\\ Scribe: \scribe}
\date{November 5, 2009}

\setaddress%

% the following hack starts the lecture numbering at 12
\setcounter{lecture}{11}
\setcounter{chapter}{11}

\lecture{Exit Problems \& Continuous Time}

\section{Exit Problem}
Let $\cale\subseteq\mathbb{X}$ be the exit set.
Once we get into the exit set we stay there no matter what control is used as input to the system.
This is given as

\begin{equation*}
\pij(u) = \begin{cases} 1, & j=i \\ 0, & j\neq i \end{cases}~\forall \uinu
\end{equation*}

Note that this means the states $i\in\cale$ are absorbing state for all $\uinu$ as given by Definition~\ref{def:absorbing}.
Also, we set $l(i,u)=0~\forall \uinu,~\forall i\in\cale$.

In the gamling example,~\ref{ex:gambling}, we have $\cale=\{1,N\}$ or when one player runs out of money.
The Markov chain can continue when the state enters the exit set but nothing will change.
At that point we could switch to a different criteria like how much the players enjoy gambling in order to continue.

We represent the time that the exit set is entered by the random variable

\begin{equation*}
\tau_x(\mu) = \min\{t\geq0 | \xi_t\in\cale\}
\end{equation*}

with $\xi_0=x$ and $\mu$ is the feedback controller.
Then the payoff/cost-criterion and value function are
\begin{align*}
J(i,\mu) &= E\left\lbrace\sum_{t=0}^{\tau_i(\mu)}l(\xi_t,\mu_t(\xi_t)) + \vp(\xi_t)\right\rbrace \\
V(i) &= \inf_{\muinm}J(i,\mu)
\end{align*}
where $\vp(\xi_t)$ is the exit cost.

Since $\tau_x(\mu)$ is a random variable we need to make the assumption that
\begin{align}
\label{eq:tauassumption}
\exists~\epsilon>0 \text{~s.t.~} \sum_{j\in\cale}\pij(u)>\epsilon~\forall i\in\mathbb{X},~\forall \uinu
\end{align}
A better assumption would be that there exists a $\bar{t}<\infty$ and $\epsilon>0$ such that

\begin{equation*}
\sum_{j\in\cale}\sum_{t=0}^t{(\mathbb{P}^t(u_t))}_{i,j}>\epsilon~\forall i\in\mathbb{X},~\forall u_t:\mathbb{X}\to\mathcal{U}~\forall t
\end{equation*}

However, that is a very complicated assumption to enforce so we will not consider it for now.

(\ref{eq:tauassumption}) is used to make sure that states exist before we use those states for a solution.

Suppose $0\leq l(i,u)\leq \bar{L}~\forall i,u$ and $0\leq \vp(i) \leq \bar{\vp}~\forall i$, then $V(i)\geq0~\forall i$.
Now we can look at the cost function to see
\begin{align}
\label{eq:exitcost}
J(i,u) &\leq E\left\lbrace \left[\sum_{t=0}^{\tau_i}\tau\right] + \bar{\vp}\right\rbrace \nonumber \\
&= E[\bar{L}\tau_i+\bar{\vp}] \nonumber \\
&= \sum_{\hat{t}=0}^\infty\left[\bar{L}\hat{t}+\bar{\vp}\right]\cdot P(\tau_i=\hat{t})
\end{align}
We have made use of
\begin{align}
\label{eq:exitprob}
P(\tau_i=\hat{t}) &= P(\xi_t\in\mathbb{X}\backslash\cale,~\forall t\in]0,\hat{t}-1[, \xi_t\in\cale) \nonumber \\% chktex 9
&\leq P(\xi_t\in\mathbb{X}\backslash\cale~\forall t\in]0,\hat{t}-1[) \nonumber \\% chktex 9
&\leq {(1-\epsilon)}^{\hat{t}-1}
\end{align}
Substituting (\ref{eq:exitprob}) into (\ref{eq:exitcost}) yields

\begin{equation*}
J(i,\mu) \leq \sum_{t=0}^\infty (\bar{L}\hat{t}-\bar{\vp}){(1-\epsilon)}^{\hat{t}-1}<\infty
\end{equation*}

In this equation we are looking at the space where the exit criteria exist.
On the exit set the value is simply $V(i)=\vp(i)$.
On $\mathbb{X}\backslash\cale$ (in the set $\mathbb{X}$ but excluding the exit set $\cale$) the DPE is

\begin{equation*}
V(i) = \min_{\uinu}\left\lbrace l(i,u) + \sum_{\jinxe}\pij(u)V(j) + \sum_{\jine}\pij(u)\vp(j)\right\rbrace \doteq \calg[V](i)
\end{equation*}


\section{Value Iteration}
If $\vp(i)\geq0~\forall i$, then we will start with $V(i)=0~\forall i$ because we want to start at a value less than the exit cost.
What do we need for the contraction operator? Think of $V:\xnote\to\mathbb{R}$.
Then, let $||V||_\infty = \max_{i\in\xnote}|V(i)|$.
We claim that $\calg$ is a contraction with respect to this norm.

\begin{proof}
Let $V,\tilde{V}\in\xnote$.
Then
\begin{align*}
&||\calg[V]-\calg[\tilde{V}]||_\infty = \\
&\quad = \max_{i\in\xnote}\left\lbrace \left| \min_{\uinu}\left\lbrace l(i,u) + \sum_{\jinxe}\pij(u)V(j) + \sum_{j\in\cale}\pij(u)\vp(j)\right\rbrace \right.\right. \\
&\left.\left.\qquad - \min_{\uinu}\left\lbrace l(i,u) + \sum_{\jinxe}\pij(u)\tilde{V}(j) + \sum_{j\in\cale}\pij(u)\vp(j) \right\rbrace\right|\right\rbrace \\
&\quad\leq \max_{i\in\xnote} \max_{\uinu} \left|\sum_{\jinxe}\pij(u)V(j) - \sum_{\jinxe}\pij(u)\tilde{V}(j)\right| \\
&\quad= \max_{i,u} \left| \sum_{\jinxe}\pij(u)[V(j)-\tilde{V}(j)]\right| \\
&\quad\leq \max_{i,u} \sum_{\jinxe}\pij(u)|V(j)-\tilde{V}(j)| \\
&\quad\leq \min_{i,u} \left\lbrace \sum_{\jinxe}\pij(u)\right\rbrace ||V-\tilde{V}||_\infty \\
&\quad\leq (1-\epsilon)||V-\tilde{V}||_\infty
\end{align*}
The last step was accomplished because $\sum_{j\in\cale}\pij(u)>\epsilon$ so what is left is $\sum_{\jinxe}\pij(u)\leq1-\epsilon$ because they are all probabilities that add up to $1$.
\end{proof}

\section{Continuous Time, Continuous Space, Deterministic Control}
The dynamics and initial conditions are given by
\begin{align}
\label{eq:ctcsdynamics}
\dot{\xi}_t = F(\xi_t,u_t), \qquad \xi_s=x\in\mathbb{R}^n
\end{align}

Suppose

\begin{equation*}
\mathcal{M}_{s,t} = \left\lbrace\mu:[s,t]\times\mathbb{R}^n\to\mathcal{U}\subseteq\mathcal{R}^k | \int_s^T||\mu_k(\xi_t)||^2dt<\infty~\forall \xi_s=x\right\rbrace
\end{equation*}

is the set of all feedback controllers.
Note that the conditional part of the above expression means that the system does not have an infinite amount of energy.
Then the cost function and the value function, with superscript $F$ representing feedback controllers, are found as
\begin{align*}
J^F&:[0,t]\times\mathbb{R}^n\times\mathcal{M}_{s,t}\to\mathbb{R} \\
J^F(s,x,\mu) &= \int_s^T l(\xi_t,\mu_t(\xi_t))dt + \vp(\xi_T) \\
V^F(s,x) &= \inf_{\muinm_{s,t}} J(s,x,\mu)
\end{align*}

\section{Game Theory, Non-linear $H_\infty$}
If the continuous time, continuous space controls are considered with stochastic systems then we need to use game theory, specifically $H_\infty$-type games.
The dynamics and initial conditions are given by
\begin{align*}
\dot{\xi}_t = f(\xi_t,u_t) + \sigma(\xi_t)w_t, \qquad \xi_0=x
\end{align*}
where $u_t$ is the control and $w_t$ is a disturbance.
The controller space is given by

\begin{equation*}
\mathcal{M}_0 = \left\lbrace \mu:\mathbb{R}^n\to\mathbb{R}^k~|~||\mu_0(\xi_0)||^2_{\lT}<\infty~\forall T<\infty\right\rbrace
\end{equation*}

where

\begin{equation*}
||u||^2_{\lT}\doteq\int_0^T||u_t||^2dt
\end{equation*}

We take

\begin{equation*}
\mathcal{W}=\left\lbrace w:[0,\infty)\to\mathbb{R}^n~|~||w_0||^2_{\lT}<\infty~\forall T<\infty \right\rbrace% chktex 9
\end{equation*}

In this context we define the value function using
\begin{align*}
J(x,T,\mu,w) &= \int_0^T l(\xi_t,\mu_t(\xi_t)) - \frac{\gamma^2}{2}||w_t||2dt \\
V(x) &= \inf_{\mu\in\mathcal{M}_0}\sup_{w\in\mathcal{W}_0}\sup_{T<\infty} J(x,T,\mu,w)
\end{align*}
Note that we are only considering zero-sum games.

Suppose there exists an optimal control, $\mu^\ast$.
Then
\begin{align*}
&V(x) = \sup_{w\in\mathcal{W}_0}\sup_{T<\infty}J(x,T,\mu^\ast,w) \\
\Rightarrow &V(x) \geq \int_0^T l(\xi_t,\mu^\ast(\xi_t)) - \frac{\gamma^2}{2}|w_t|^2dt~\forall w\in\mathcal{W}_0,~\forall T \\
\Rightarrow &\int_0^T l(\xi_t,\mu^\ast(\xi_t)) \leq V(x) + \frac{\gamma^2}{2}||w||_{\lT}
\end{align*}
If $l(x,u)  = \frac{1}{2}|x|^2+\frac{1}{}|u|^2$ then

\begin{equation*}
\frac{1}{2}||\xi||^2_{\lT} + \frac{1}{2}||\mu^\ast(\xi)||_{\lT}^2 \leq V(x) + \frac{\gamma^2}{2}||w||^2_{\lT}
\end{equation*}

$V(x)$ is called the \textit{available storage} and $\frac{\gamma^2}{2}$ is called the \textit{disturbance attenuation coefficient}.
We can think of $V(x)$ as the potential energy in the initial conditions.
The engineer gets to pick $\gamma$ so that the system is bounded and such that a solution will exist.

\section{Deterministic Control}
Shifting back to deterministic systems recall that the dynamics and initial conditions were given by (\ref{eq:ctcsdynamics}).
We have that if there exists a $K$ satisfying
\begin{align}
\label{eq:lipschitz}
||f(x,u)-f(y,u)||\leq K|x-y|
\end{align}
then there exists a unique solution to (\ref{eq:ctcsdynamics}).
This is known as the Lipschitz condition.
Above, we wanted to find finite $L_2$-norm controllers.
We still need to have that
\begin{align}
\label{eq:controlspace}
\mathcal{M}_s = \left\lbrace \mu:[0,T]\times\mathbb{R}^n\to\mathcal{U}~|~||\mu(\xi)||^2_{\lT}<\infty,~\exists~! \text{~sol~of~\ref{eq:ctcsdynamics} } \forall s,x \right\rbrace
\end{align}
However, (\ref{eq:lipschitz}) does not imply that there exists a solution for the feedback controller, $\mu$, only that there exists a unique solution for the open-loop input $u_t$.

\begin{example}
Let $\dot{\xi}=u$ and $\xi_s=x$ have a solution for all $L_2$ $u$, but let
\begin{align}
\label{eq:12ex}
\mu_t(x)=\frac{3}{2}x^{\frac{1}{3}}
\end{align}
then

\begin{equation*}
\dot{\xi}=\frac{3}{2}\xi^{\frac{1}{3}}
\end{equation*}

doesn't satisfy (\ref{eq:lipschitz}) anymore.
We find that

\begin{equation*}
\xi_t^0=t^{\frac{3}{2}} \Rightarrow \dot{\xi}^0=\frac{3}{2}t^{\frac{1}{2}} = \frac{3}{2}{(\xi_t^0)}^{\frac{1}{3}}
\end{equation*}

which shows that $\xi^0$ is a solution to (\ref{eq:12ex}) with initial conditions $\xi_0^0=0$.
But

\begin{equation*}
\xi_t^\alpha = \begin{cases} 0, & t\in[0,\alpha] \\ {(t-\alpha)}^{\frac{3}{2}}, & t\in[\alpha,\infty) \end{cases}% chktex 9
\end{equation*}

is also a solution for all $\alpha\geq0$.

This shows that we have to require there be a unique solution for the feedback controllers.
$\lozenge$
\end{example}% chktex 17
